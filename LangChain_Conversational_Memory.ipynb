{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scorzo/LangChain_Conversational_Memory/blob/main/LangChain_Conversational_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d3e2148",
      "metadata": {
        "id": "2d3e2148"
      },
      "source": [
        "# Install LangChain\n",
        "Install the LangChain library which is needed for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fba9e5",
      "metadata": {
        "id": "a8fba9e5"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e787e3e3",
      "metadata": {
        "id": "e787e3e3"
      },
      "source": [
        "# Import Necessary Libraries\n",
        "Import LangChain and other necessary libraries for the conversation AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e116d71",
      "metadata": {
        "id": "1e116d71"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFaceAPI\n",
        "from langchain.chains import Chain\n",
        "from langchain.prompts import ConversationHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd31c52d",
      "metadata": {
        "id": "cd31c52d"
      },
      "source": [
        "# Setup Language Model and Conversation History\n",
        "Initialize the language model and setup conversation history management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d02767f",
      "metadata": {
        "id": "6d02767f"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceAPI(model_name='gpt-3', api_key='your-api-key')\n",
        "conversation_history = ConversationHistory()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a21fc4cf",
      "metadata": {
        "id": "a21fc4cf"
      },
      "source": [
        "# Create a Chain with Components\n",
        "Create a chain with components for managing conversation history and language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ae0a98",
      "metadata": {
        "id": "b7ae0a98"
      },
      "outputs": [],
      "source": [
        "chain = Chain(components=[conversation_history, llm])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c95b381",
      "metadata": {
        "id": "4c95b381"
      },
      "source": [
        "# Implement a Conversational Loop with Memory\n",
        "Create a conversational loop that updates and utilizes the conversation history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec17523f",
      "metadata": {
        "id": "ec17523f"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_input = input('You: ')\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    conversation_history.add_user_input(user_input)\n",
        "    response = chain.run()\n",
        "    print('AI:', response)\n",
        "\n",
        "    conversation_history.add_model_output(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}